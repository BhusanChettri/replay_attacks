Performing global mean and variance normalization
After randomizing, total batches and kept batches: 187,149
Performing global mean and variance normalization
Training model on  mag_spec
In train, spec type is :  mag_spec
======================== CNN ARCHITECTURE ==============================

Conv1  Tensor("conv1/Maximum:0", shape=(?, 100, 257, 64), dtype=float32, device=/device:GPU:0)
Conv2  Tensor("conv2/Maximum:0", shape=(?, 100, 257, 64), dtype=float32, device=/device:GPU:0)
Conv2  Tensor("conv3/Maximum:0", shape=(?, 100, 257, 64), dtype=float32, device=/device:GPU:0)
Pool1 layer shape =  Tensor("MaxPool:0", shape=(?, 1, 257, 64), dtype=float32, device=/device:GPU:0)
Shape of FC1 =  (?, 128)
Shape of FC2 =  (?, 128)
Shape of FC3 =  (?, 128)
Output layer shape =  (?, 2)
======================== CNN ARCHITECTURE ==============================

Using ADAM optimizer
Graph launched successfully..
For training we use only: 296 batches (size=32), out of 296
For validation we use only: 149 batches out of 149
total train batches and validateNow point = 296,148
***********************  Epoch: 1  ***************************
Learning rate used in Epoch 0 is = 0.0001
Traceback (most recent call last):
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1022, in _do_call
    return fn(*args)
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1004, in _run_fn
    status, run_metadata)
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/contextlib.py", line 89, in __exit__
    next(self.gen)
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py", line 469, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[32,100,257,128]
	 [[Node: conv1/Wx_plus_b/Conv2D = Conv2D[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](_recv_Placeholder_5_0/_13, weights/conv1_W/read)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "train_cnn_pindArch_withReg_2targets.py", line 153, in <module>
    trainCNN_on_trainData()
  File "train_cnn_pindArch_withReg_2targets.py", line 148, in trainCNN_on_trainData
    targets,augment)#,trainPercentage,valPercentage)                                                                                                                                        
  File "/homes/bc305/myphd/stage2/deeplearning.experiment1/code_in_git/replay_attacks/final_code/model.py", line 308, in train
    keep_prob2:drop2,keep_prob3:drop3,tst:False,itr:i,eps:epsilon,lr:learning_rate})
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 767, in run
    run_metadata_ptr)
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 965, in _run
    feed_dict_string, options, run_metadata)
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1015, in _do_run
    target_list, options, run_metadata)
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1035, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[32,100,257,128]
	 [[Node: conv1/Wx_plus_b/Conv2D = Conv2D[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](_recv_Placeholder_5_0/_13, weights/conv1_W/read)]]

Caused by op 'conv1/Wx_plus_b/Conv2D', defined at:
  File "train_cnn_pindArch_withReg_2targets.py", line 153, in <module>
    trainCNN_on_trainData()
  File "train_cnn_pindArch_withReg_2targets.py", line 148, in trainCNN_on_trainData
    targets,augment)#,trainPercentage,valPercentage)
  File "/homes/bc305/myphd/stage2/deeplearning.experiment1/code_in_git/replay_attacks/final_code/model.py", line 195, in train
    _, model_prediction,network_weights,activations,biases= nn_architecture.cnnModel1(input_type,trainSize,input_data, act,init_type,num_classes,fftSize,padding,keep_prob1,keep_prob2,keep_prob3)
  File "/homes/bc305/myphd/stage2/deeplearning.experiment1/code_in_git/replay_attacks/final_code/nn_architecture.py", line 80, in cnnModel1
    conv1,w1,b1 = conv_layer(input_placeholder, [3,f,1,128], [128], [1,1,1,1],'conv1',padding,activation,init)
  File "/homes/bc305/myphd/stage2/deeplearning.experiment1/code_in_git/replay_attacks/final_code/network.py", line 139, in conv_layer
    conv = tf.nn.conv2d(input_tensor, weights, strides=stride_shape, padding='SAME') + biases
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py", line 396, in conv2d
    data_format=data_format, name=name)
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 763, in apply_op
    op_def=op_def)
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 2395, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1264, in __init__
    self._traceback = _extract_stack()

ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,100,257,128]
	 [[Node: conv1/Wx_plus_b/Conv2D = Conv2D[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](_recv_Placeholder_5_0/_13, weights/conv1_W/read)]]

Performing global mean and variance normalization
After randomizing, total batches and kept batches: 187,149
Performing global mean and variance normalization
Training model on  mag_spec
In train, spec type is :  mag_spec
======================== CNN ARCHITECTURE ==============================

Conv1  Tensor("conv1/Maximum:0", shape=(?, 100, 257, 64), dtype=float32, device=/device:GPU:0)
Conv2  Tensor("conv2/Maximum:0", shape=(?, 100, 257, 64), dtype=float32, device=/device:GPU:0)
Conv2  Tensor("conv3/Maximum:0", shape=(?, 100, 257, 64), dtype=float32, device=/device:GPU:0)
Pool1 layer shape =  Tensor("MaxPool:0", shape=(?, 1, 257, 64), dtype=float32, device=/device:GPU:0)
Shape of FC1 =  (?, 128)
Shape of FC2 =  (?, 128)
Shape of FC3 =  (?, 128)
Output layer shape =  (?, 2)
======================== CNN ARCHITECTURE ==============================

Using ADAM optimizer
Graph launched successfully..
For training we use only: 296 batches (size=32), out of 296
For validation we use only: 149 batches out of 149
total train batches and validateNow point = 296,148
***********************  Epoch: 1  ***************************
Learning rate used in Epoch 0 is = 0.0001
Traceback (most recent call last):
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1022, in _do_call
    return fn(*args)
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1004, in _run_fn
    status, run_metadata)
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/contextlib.py", line 89, in __exit__
    next(self.gen)
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py", line 469, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[32,100,257,128]
	 [[Node: conv1/Wx_plus_b/Conv2D = Conv2D[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](_recv_Placeholder_5_0/_13, weights/conv1_W/read)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "train_cnn_pindArch_withReg_2targets.py", line 153, in <module>
    trainCNN_on_trainData()
  File "train_cnn_pindArch_withReg_2targets.py", line 148, in trainCNN_on_trainData
    targets,augment)#,trainPercentage,valPercentage)                                                                                                                                        
  File "/homes/bc305/myphd/stage2/deeplearning.experiment1/code_in_git/replay_attacks/final_code/model.py", line 308, in train
    keep_prob2:drop2,keep_prob3:drop3,tst:False,itr:i,eps:epsilon,lr:learning_rate})
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 767, in run
    run_metadata_ptr)
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 965, in _run
    feed_dict_string, options, run_metadata)
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1015, in _do_run
    target_list, options, run_metadata)
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1035, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[32,100,257,128]
	 [[Node: conv1/Wx_plus_b/Conv2D = Conv2D[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](_recv_Placeholder_5_0/_13, weights/conv1_W/read)]]

Caused by op 'conv1/Wx_plus_b/Conv2D', defined at:
  File "train_cnn_pindArch_withReg_2targets.py", line 153, in <module>
    trainCNN_on_trainData()
  File "train_cnn_pindArch_withReg_2targets.py", line 148, in trainCNN_on_trainData
    targets,augment)#,trainPercentage,valPercentage)
  File "/homes/bc305/myphd/stage2/deeplearning.experiment1/code_in_git/replay_attacks/final_code/model.py", line 195, in train
    _, model_prediction,network_weights,activations,biases= nn_architecture.cnnModel1(input_type,trainSize,input_data, act,init_type,num_classes,fftSize,padding,keep_prob1,keep_prob2,keep_prob3)
  File "/homes/bc305/myphd/stage2/deeplearning.experiment1/code_in_git/replay_attacks/final_code/nn_architecture.py", line 80, in cnnModel1
    conv1,w1,b1 = conv_layer(input_placeholder, [3,f,1,128], [128], [1,1,1,1],'conv1',padding,activation,init)
  File "/homes/bc305/myphd/stage2/deeplearning.experiment1/code_in_git/replay_attacks/final_code/network.py", line 139, in conv_layer
    conv = tf.nn.conv2d(input_tensor, weights, strides=stride_shape, padding='SAME') + biases
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py", line 396, in conv2d
    data_format=data_format, name=name)
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 763, in apply_op
    op_def=op_def)
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 2395, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1264, in __init__
    self._traceback = _extract_stack()

ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,100,257,128]
	 [[Node: conv1/Wx_plus_b/Conv2D = Conv2D[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](_recv_Placeholder_5_0/_13, weights/conv1_W/read)]]

Performing global mean and variance normalization
After randomizing, total batches and kept batches: 187,149
Performing global mean and variance normalization
Training model on  mag_spec
In train, spec type is :  mag_spec
======================== CNN ARCHITECTURE ==============================

Conv1  Tensor("conv1/Maximum:0", shape=(?, 100, 257, 64), dtype=float32, device=/device:GPU:0)
Conv2  Tensor("conv2/Maximum:0", shape=(?, 100, 257, 64), dtype=float32, device=/device:GPU:0)
Conv2  Tensor("conv3/Maximum:0", shape=(?, 100, 257, 64), dtype=float32, device=/device:GPU:0)
Pool1 layer shape =  Tensor("MaxPool:0", shape=(?, 1, 257, 64), dtype=float32, device=/device:GPU:0)
Shape of FC1 =  (?, 128)
Shape of FC2 =  (?, 128)
Shape of FC3 =  (?, 128)
Output layer shape =  (?, 2)
======================== CNN ARCHITECTURE ==============================

Using ADAM optimizer
Graph launched successfully..
For training we use only: 296 batches (size=32), out of 296
For validation we use only: 149 batches out of 149
total train batches and validateNow point = 296,148
***********************  Epoch: 1  ***************************
Learning rate used in Epoch 0 is = 0.0001
Traceback (most recent call last):
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1022, in _do_call
    return fn(*args)
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1004, in _run_fn
    status, run_metadata)
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/contextlib.py", line 89, in __exit__
    next(self.gen)
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py", line 469, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[32,100,257,128]
	 [[Node: conv1/Wx_plus_b/Conv2D = Conv2D[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](_recv_Placeholder_5_0/_13, weights/conv1_W/read)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "train_cnn_pindArch_withReg_2targets.py", line 153, in <module>
    trainCNN_on_trainData()
  File "train_cnn_pindArch_withReg_2targets.py", line 148, in trainCNN_on_trainData
    targets,augment)#,trainPercentage,valPercentage)                                                                                                                                        
  File "/homes/bc305/myphd/stage2/deeplearning.experiment1/code_in_git/replay_attacks/final_code/model.py", line 308, in train
    keep_prob2:drop2,keep_prob3:drop3,tst:False,itr:i,eps:epsilon,lr:learning_rate})
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 767, in run
    run_metadata_ptr)
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 965, in _run
    feed_dict_string, options, run_metadata)
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1015, in _do_run
    target_list, options, run_metadata)
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1035, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[32,100,257,128]
	 [[Node: conv1/Wx_plus_b/Conv2D = Conv2D[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](_recv_Placeholder_5_0/_13, weights/conv1_W/read)]]

Caused by op 'conv1/Wx_plus_b/Conv2D', defined at:
  File "train_cnn_pindArch_withReg_2targets.py", line 153, in <module>
    trainCNN_on_trainData()
  File "train_cnn_pindArch_withReg_2targets.py", line 148, in trainCNN_on_trainData
    targets,augment)#,trainPercentage,valPercentage)
  File "/homes/bc305/myphd/stage2/deeplearning.experiment1/code_in_git/replay_attacks/final_code/model.py", line 195, in train
    _, model_prediction,network_weights,activations,biases= nn_architecture.cnnModel1(input_type,trainSize,input_data, act,init_type,num_classes,fftSize,padding,keep_prob1,keep_prob2,keep_prob3)
  File "/homes/bc305/myphd/stage2/deeplearning.experiment1/code_in_git/replay_attacks/final_code/nn_architecture.py", line 80, in cnnModel1
    conv1,w1,b1 = conv_layer(input_placeholder, [3,f,1,128], [128], [1,1,1,1],'conv1',padding,activation,init)
  File "/homes/bc305/myphd/stage2/deeplearning.experiment1/code_in_git/replay_attacks/final_code/network.py", line 139, in conv_layer
    conv = tf.nn.conv2d(input_tensor, weights, strides=stride_shape, padding='SAME') + biases
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py", line 396, in conv2d
    data_format=data_format, name=name)
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 763, in apply_op
    op_def=op_def)
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 2395, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File "/homes/bc305/sw/python/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1264, in __init__
    self._traceback = _extract_stack()

ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,100,257,128]
	 [[Node: conv1/Wx_plus_b/Conv2D = Conv2D[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](_recv_Placeholder_5_0/_13, weights/conv1_W/read)]]

